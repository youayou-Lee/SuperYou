法律案件 RAG 设计文档（证据型问答，基于 output.pdf 的讯问笔录场景）

你要做的是“可核验的证据检索 + 受控生成”，不是聊天机器人。否则一旦金额/日期答错，系统在法律场景里就是不可用。

0. 背景与目标

输入：案件材料 PDF（当前示例是 8 页《讯问笔录》，包含基础信息与大量问答对）。

output


输出：对问题给出结论 + 可追溯证据（页码/段落定位），并对冲突与不确定性显式说明。

明确的成功定义（你已认可的“好”）

可核验：证据片段 + 页码/段落定位

数字/时间零容错

冲突显式化

召回优先、再精排

解析与版面保真

结构化切块（基础信息 + 问答对）

证据粒度元数据

混合检索 + 重排

固定输出结构

三类 benchmark（事实/证据集合/冲突与缺口）

1. 总体架构（推荐最小可行但可扩展）
1.1 三层数据形态（必须分清）

原始层（Raw Evidence）：PDF 原文 + 页面图像（用于审计与回溯）

证据层（Evidence Chunks）：结构化切块 + 位置锚点（页码/段落/坐标）

派生层（Derived Facts，可选但强烈建议）：从证据抽取的结构化事实（金额、时间线、人物关系）

只做“向量库+LLM”会导致：证据定位缺失、数字被改写、冲突被“综合掉”。

1.2 检索与生成流水线（多阶段）

Query 解析（意图：事实/证据/冲突；实体：人名/金额/日期/地点/行为）

混合召回：BM25（字面）+ 向量（语义）

重排：cross-encoder reranker，把“看起来相关”的排到前面

证据聚合（去重、按页排序、补全上下文）

约束生成：固定结构输出 + 强制引用 + 数字/时间校验

冲突检测与显式报告

审计落盘（可回放每一步）

2. 数据解析与版面保真（你系统最容易翻车的环节）
2.1 现实问题：这份 PDF 存在明显 OCR 噪声

示例里“时间”字段被识别成大量乱码（如“2023 年工月里旦日…”），说明文本层质量不稳定。

output


结论：你必须做“解析质量门禁”，否则后续“零容错”不可能达成。

2.2 解析策略（按优先级）

优先 1：可提取的 PDF 文本层 + 版面信息

提取每页文本

保留：页码、行号/段落号、（若可得）bbox 坐标

优先 2：如果文本层脏/缺失 → OCR 重建（带坐标）

做 OCR 时必须输出：文本 + 坐标（用于高亮证据）

同时保留原页图像，证据展示用“高亮框”而不是只贴文字

2.3 解析质量门禁（强制）

对每页计算：

字符可读率（乱码占比）

关键字段命中率（“问：”“答：”“第 X 页 共 Y 页”等模式）

数字/日期模式完整度（YYYY、金额）

低于阈值：

标记该页为 needs_ocr=true

或直接阻断上线（你要的是可审计系统，不是碰碰运气）

3. 结构化切块（讯问笔录专用：基础信息 + 问答对）
3.1 切块目标

一个 chunk = 一个可引用的证据单元

chunk 过大：检索命中但生成引用混乱

chunk 过小：上下文断裂，证据不足

3.2 建议切块规则

A. 基础信息块（Header Block）

时间、地点、讯问单位、讯问人员、记录人、被讯问人基本信息等（作为一个或多个块）

这些信息常用于“程序合法性/身份核验”类问题
示例：文件头部包含时间地点、单位、被讯问人信息等。

output

B. 问答对块（QA Pair Chunk）

以正则锚点切分：问： 到下一个 问： 之前

每块内部保留原顺序

对“长答复”允许二级子块，但要保持同一问答链路 id

C. 时间线/金额密集块（Fact-Dense Subchunk，可选）
对包含多笔转账/退款的段落，额外生成“事实子块”，避免模型在长段里抄错数字。
示例：该笔录明确列出收款与退款的日期与金额（17000/13000/6000/6000；退款 15000/3000；欠款 24000）。

output

4. 证据粒度元数据（没有它就谈不上“可核验”）
4.1 最小元数据 schema（建议）
{
  "doc_id": "output",
  "doc_type": "interrogation_transcript",
  "chunk_id": "output_p4_qa_017",
  "page_start": 4,
  "page_end": 4,
  "span": {"char_start": 1203, "char_end": 1688},
  "bbox": [{"page": 4, "x1": 72, "y1": 310, "x2": 520, "y2": 610}],
  "section": "qa_pair",
  "speaker": "answer",
  "entities": {
    "persons": ["嫌疑人A", "当事人B"],
    "orgs": ["某派出所"],
    "locations": ["某地"],
    "dates": ["2020-06-05", "2020-08-31", "2020-11-24"],
    "amounts": [17000, 13000, 6000, 6000, 15000, 3000, 24000, 42000]
  },
  "tags": ["收款", "退款", "学位办理", "微信转账"],
  "pii_level": "high",
  "parse_quality": {"ocr": false, "garbled_rate": 0.03}
}

4.2 PII 策略（必须做，不然你迟早翻车）

存储层可以保留原文（审计需要），但生成层默认脱敏：

身份证/电话/详细住址/微信号 → *** 或哈希

检索可以用“受控字段”匹配（比如尾号），但输出需要权限控制

笔录中包含身份证号、电话、住址、微信号等敏感信息。

5. 索引：混合检索 + 重排（法律文本的现实解）
5.1 为什么不能只用向量

金额、日期、姓名、特定地点（店名/学校名）都是“精确字符串”。向量检索对这种信息不稳，会漏。

5.2 混合检索的具体做法

两套索引并行：

BM25（关键词）：命中“42000”“2020年11月24日”“退款”“拖欠”等

Vector（语义）：命中“退还/退款/归还”“承诺退钱”“无法办理学位”等同义表达

召回策略（建议）

BM25 TopK1（例如 50）+ Vector TopK2（例如 50）→ 合并去重 → 交给 reranker 排序取 TopN（例如 8～15）

5.3 重排（reranker）为什么是“必须”

法律问答最怕“看起来相关但其实不对”的 chunk 排在前面。重排可以显著减少这种错证据。

6. 数字/时间零容错：别指望 LLM 自觉
6.1 强制“数字来自证据，不来自想象”

你的生成系统必须满足：

任何金额/日期出现在证据摘录中

并通过后处理校验（regex 抽取 + 一致性检查）

6.2 一致性校验（示例：这份材料可以做强校验）

材料给出收款构成与退款构成：

output

收款：17000 + 13000 + 6000 + 6000 = 42000

17000 + 13000 = 30000

30000 + 6000 = 36000

36000 + 6000 = 42000

退款：15000 + 3000 = 18000

欠款：42000 − 18000 = 24000

做到这一步，你的系统才配叫“零容错”。否则就是“会说话的检索”。

6.3 时间规范化（必须）

统一转成 ISO：2020-11-24

对“左右/约/某日”等不确定时间，标注 date_precision = "approx"，避免模型把“约”说成“确定”。

7. 冲突显式化（你要让系统敢说“不一致”）
7.1 冲突类型

事实冲突：两处证据给出不同金额/日期/人名

叙述冲突：同一人前后口供矛盾

材料缺口：问到了但答复是“忘了/不详”

示例：关于资金用途，答复是“用于请客送礼…具体…都忘记了”。

output


这类问题如果模型编细节，你系统就直接报废。

7.2 冲突输出规范（固定模板的一部分）

“发现冲突/不一致：A 证据… vs B 证据…”

“当前材料无法确定：原因（证据显示‘忘记/不详’）”

8. 固定输出结构（把生成关进笼子里）
8.1 推荐输出格式（强制）

结论：一句话回答

证据：逐条列出（页码 + 摘录）

计算/推导（如适用）：只允许基于证据做算术或排序

冲突/不确定性：明确写出

材料缺口：若未找到，写“未在材料中找到”并说明检索范围

8.2 生成提示词要点（你可以照抄思路）

“只允许使用证据块中的信息”

“禁止补充背景、禁止猜测”

“金额/日期必须逐字出现在证据摘录中”

“找不到就拒答，不要圆”

9. 三类 Benchmark（评测不是装饰，是刹车系统）
9.1 数据格式建议（可机器跑）
{
  "id": "fact_001",
  "type": "fact_exact",
  "question": "当事人B总共给了多少钱？",
  "expected": {"amount_total": 42000},
  "required_evidence": [{"page": 4, "must_include": "42000"}],
  "scoring": {"numeric_exact": true, "citation_required": true}
}

9.2 三类题库怎么设计（每类都要“能打脸”）

A. 事实型（唯一答案，硬判分）

金额、日期、次数、地点、是否认罪认罚等
例如：笔录中出现“涉嫌诈骗传唤”“是否认罪认罚”的问答。

output


指标：

数字/日期 exact match = 1/0

引用页码正确

允许拒答但要判定是否该拒答

B. 证据集合型（答案=多条证据）

“有哪些证据表明其承诺退款/已退款/仍欠款？”

“有哪些证据涉及资金用途说明？”
指标：

Evidence Recall@K（关键证据是否都被召回）

Evidence Precision（是否混入无关块）

引用覆盖度（关键结论至少 2 条证据更稳）

C. 冲突/缺口型（重点评测“不会编”）

“42000 用到哪里了？给了谁？买了什么？”
正确回答应是“不明确/记不清”，并引用原话。

output


指标：

正确拒答率（Abstention correctness）

幻觉率（Hallucination rate）= 0 才合格

10. 工程化：审计、回放、回归（不上这些你只能靠运气）
10.1 必须落盘的日志

用户问题（脱敏）

召回结果（BM25/Vector 各自 TopK）

重排后的 TopN（含分数）

最终引用的 chunk_id + 页码

生成输出

数字/时间校验结果（通过/失败原因）

10.2 回归测试机制

每次更换 embedding / reranker / prompt / chunk 策略，都跑 benchmark

任何一条“事实型题”从 100% 掉下来：直接阻断发布

11. MVP 交付清单（按优先级，别自嗨）

解析质量门禁 + 页码/段落锚点（否则可核验是假话）

讯问笔录切块（基础信息 + 问答对）

元数据与 PII 脱敏输出

Hybrid 检索 + rerank

固定输出结构 + 数字/时间校验

三类 benchmark + 自动回归

（可选增强）结构化事实表（时间线/金额流水/人物关系）用于更强的零容错
